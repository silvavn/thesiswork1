{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import CSV file and create the database\n",
    "#csv_filename = \"age_specific_fertility_rates.csv\"\n",
    "csv_filename = \"midyear_population_age_country_code.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "#the line below is necessary only if the dataset is not ordered by year\n",
    "#df = df.sort_values(['year'], ascending=[True])\n",
    "snap_headers = np.unique(df['year']) #the filter that will define the snapshot range\n",
    "#features = [i for i in df if 'fertility' in i]\n",
    "features = [i for i in df if 'population' in i]\n",
    "snapshots = [df[df['year'] == i] for i in snap_headers]\n",
    "timeline = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datapoint:\n",
    "    def __init__(self, position, label=None):\n",
    "        self.position = position\n",
    "        self.label = label\n",
    "\n",
    "    @property\n",
    "    def position(self):\n",
    "        return self.__position\n",
    "\n",
    "    @position.setter\n",
    "    def position(self, position):\n",
    "        self.__position = position\n",
    "    \n",
    "    def get_fill(self):\n",
    "        colors = [GREEN,BLUE,YELLOW, WHITE, CYAN, MAGENTA, GRAY]\n",
    "        try:\n",
    "            return colors[self.label]\n",
    "        except:\n",
    "            return RED\n",
    "    \n",
    "    def Print(self):\n",
    "        print(\"Label: {}\\nFeature Vector: {}\\n\".format(self.label, self.position))\n",
    "\n",
    "    def draw(self, canvas):\n",
    "        if len(self.position) != 2: return # does not render if data is not bidimensional\n",
    "        #print(self.position)\n",
    "        canvas.create_oval(int(self.position[0])-datapoint_radius, \n",
    "            self.position[1]-datapoint_radius, \n",
    "            self.position[0]+datapoint_radius, \n",
    "            self.position[1]+datapoint_radius, \n",
    "            fill=self.get_fill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util functions\n",
    "def myplot(X, db, d):\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([0,400])\n",
    "    axes.set_ylim([0,400])\n",
    "    \n",
    "    plt.scatter(X[features[1]], X[features[2]], c=db, cmap='tab20', alpha=1, s =10)\n",
    "    plt.savefig(\"./results/{}.png\".format(str(np.unique(d['year'])[0])))\n",
    "    plt.clf()\n",
    "\n",
    "def save(filename, element):\n",
    "    pickle.dump(element, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-3e02d3218581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#db = KMeans(n_clusters=int(np.sqrt(len(d))), random_state=0).fit_predict(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtimeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDatapoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/anaconda3/lib/python3.6/site-packages/sklearn/cluster/dbscan_.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mcluster\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/anaconda3/lib/python3.6/site-packages/sklearn/cluster/dbscan_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         clust = dbscan(X, sample_weight=sample_weight,\n\u001b[0;32m--> 281\u001b[0;31m                        **self.get_params())\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_sample_indices_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclust\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_sample_indices_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/anaconda3/lib/python3.6/site-packages/sklearn/cluster/dbscan_.py\u001b[0m in \u001b[0;36mdbscan\u001b[0;34m(X, eps, min_samples, metric, metric_params, algorithm, leaf_size, p, sample_weight, n_jobs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# This has worst case O(n^2) memory complexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         neighborhoods = neighbors_model.radius_neighbors(X, eps,\n\u001b[0;32m--> 145\u001b[0;31m                                                          return_distance=False)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance)\u001b[0m\n\u001b[1;32m    623\u001b[0m                     \"or set algorithm='brute'\" % self._fit_method)\n\u001b[1;32m    624\u001b[0m             results = self._tree.query_radius(X, radius,\n\u001b[0;32m--> 625\u001b[0;31m                                               return_distance=return_distance)\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#run clustering for each snapshot\n",
    "for d in snapshots:\n",
    "    \n",
    "    #print (datapoints[1][features])\n",
    "    X = d[features].values\n",
    "    #db = KMeans(n_clusters=int(np.sqrt(len(d))), random_state=0).fit_predict(X)\n",
    "    db = DBSCAN(eps=5, min_samples=3, metric='euclidean', algorithm='auto', leaf_size=30, p=None, n_jobs=-1).fit_predict(X)\n",
    "    timeline.append([Datapoint(X[i], db[i]) for i in range(len(X))])\n",
    "        \n",
    "    #print (X)\n",
    "    #plt.scatter(X[features[0]], X[features[1]])\n",
    "    #plt.savefig(\"{}.png\".format(str(np.unique(d['year']))))\n",
    "    #db = KMeans(n_clusters=int(np.sqrt(len(d))), random_state=0).fit_predict(X)\n",
    "    \n",
    "\n",
    "    #myplot(X, db, d)\n",
    "    #print(np.unique(d['year']), np.unique(db), len(d))\n",
    "save(csv_filename[:-4], timeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
